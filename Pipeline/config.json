{
    "_documentation": {
        "description": "Configuration file for the image labeling workflow pipeline",

        "STEP 1 - Frame Extraction & Image Clustering": {
            "video_path": "Path to a video file, a folder containing videos, OR a folder containing images",
            "frame_threshold": "Similarity threshold (0-1). Higher = keep more similar frames, lower = filter aggressively",
            "target_fps": "Frames per second to extract (e.g., 3.0 = 3 frames per second). Only used for video input",
            "frame_interval": "Alternative: extract every Nth frame. Use null to use target_fps instead",
            "max_frames": "Maximum frames to extract. Use null for no limit",
            "histogram_bins": "Bins for histogram comparison. Higher = more precise similarity detection",
            "frame_prefix": "Filename prefix for extracted frames (e.g., 'frame' -> frame_0001.jpg)",
            "blur_threshold": "Laplacian variance threshold. Frames/images below this are considered blurry and skipped. Default: 100.0",
            "clustering_eps": "DBSCAN eps (max neighbor distance). null = auto-derived from 1.0 - frame_threshold",
            "clustering_min_samples": "DBSCAN min_samples parameter. Default: 2",
            "clustering_deleted_dir": "Directory where non-representative and blurry images are moved. Default: ./deleted/clustering",
            "clustering_method": "Clustering algorithm: 'sequential' (fast, for video frames) or 'dbscan' (thorough, for mixed images). null = prompt user",
            "clustering_window_size": "For sequential method: number of neighboring frames to compare. Default: 10"
        },

        "STEP 2 - Anonymization": {
            "anonymize_input_dir": "Directory containing images to anonymize (typically extracted_frames)",
            "anonymize_output_dir": "Directory where anonymized images are saved",
            "anonymizer_weights_dir": "Directory to store/load anonymizer model weights",
            "face_threshold": "Detection threshold for faces (0.0-1.0). Lower = more sensitive, may have false positives",
            "plate_threshold": "Detection threshold for license plates (0.0-1.0). Lower = more sensitive",
            "obfuscation_kernel": "Blur parameters: kernel_size,sigma,box_kernel_size (e.g., '65,3,19')"
        },

        "STEP 3 - Labeling": {
            "labeling_input_dir": "Directory containing images to label with X-AnyLabeling",
            "anylabeling_venv": "Python virtual environment name where X-AnyLabeling is installed",
            "anylabeling_repo": "Path to the X-AnyLabeling source repo (added to PYTHONPATH)",
            "deleted_empty_labels_dir": "Directory where images with empty/missing labels are moved. Default: ./deleted/empty_labels"
        },

        "STEP 4 - Consolidate": {
            "consolidated_output_dir": "Directory where images and labels are gathered together",
            "include_labels": "true = include label files, false = images only",
            "copy_files": "true = copy files, false = move files (removes from source)",
            "label_format": "Label format: 'json' (LabelMe), 'txt' (YOLO), 'xml' (Pascal VOC)"
        },

        "YOLO Training Workflow (main.py)": {
            "autolabel_input_dir": "Directory containing images to auto-label (typically extracted_frames)",
            "autolabel_confidence": "Confidence threshold for detections (0.0-1.0). Lower = more detections",
            "autolabel_iou": "IoU threshold for NMS (0.0-1.0). Lower = fewer overlapping boxes",
            "autolabel_imgsz": "Input image size for YOLO inference (e.g., 640)",
            "autolabel_device": "CUDA device (e.g., '0', '0,1', 'cpu'). Empty string = auto",
            "autolabel_delete_unlabeled": "true = remove images with no detections, false = keep all",
            "autolabel_deleted_dir": "Directory where unlabeled images are moved. Default: ./deleted/unlabeled",
            "autolabel_output_dir": "Base directory for labeled output. Input path relative to /home/aidall/Object_Detection is appended (e.g. ./autolabeled + Set3/BoundingBox/Bbox_1 â†’ ./autolabeled/Set3/BoundingBox/Bbox_1). Default: ./autolabeled",
            "yolo_train_ratio": "Train/val split ratio for YOLO conversion (0.0-1.0). Default: 0.8",
            "yolo_classes_file": "Path to classes.txt for YOLO conversion. null = auto-detect from JSON labels"
        },

        "YOLO Training (main.py Step 6)": {
            "train_epochs": "Number of training epochs. Default: 100",
            "train_batch": "Batch size (-1 for auto-batch). Default: 16",
            "train_imgsz": "Input image size (e.g., 640, 1280). Default: 640",
            "train_device": "CUDA device (e.g., '0', '0,1', 'cpu'). Empty string = auto. Default: empty",
            "train_workers": "Number of dataloader workers. Default: 8",
            "train_project": "Project directory for saving training results. Default: ./runs",
            "train_name": "Experiment name. null = auto-generated timestamp. Default: null",
            "train_resume": "Resume training from last checkpoint. Default: false",
            "train_pretrained": "Use pretrained weights. Default: true",
            "train_optimizer": "Optimizer: auto, SGD, Adam, AdamW. Default: auto",
            "train_lr0": "Initial learning rate. Default: 0.01",
            "train_patience": "Early stopping patience (epochs). 0 = disabled. Default: 50",
            "train_cache": "Cache images in RAM for faster training. Default: false",
            "train_amp": "Use Automatic Mixed Precision (AMP). Default: true",
            "train_augment": "Enable data augmentation. Default: true"
        }
    },

    "video_path": "",
    "frame_threshold": 0.9,
    "target_fps": 3.0,
    "frame_interval": null,
    "max_frames": null,
    "histogram_bins": 32,
    "frame_prefix": "frame",
    "blur_threshold": 80.0,
    "clustering_eps": null,
    "clustering_min_samples": 2,
    "clustering_deleted_dir": "./deleted/clustering",
    "clustering_method": null,
    "clustering_window_size": 10,

    "image_extensions": ["jpg", "jpeg", "png", "bmp", "tiff", "webp"],

    "anonymize_input_dir": "./extracted_frames",
    "anonymize_output_dir": "./anonymized_images",
    "anonymizer_weights_dir": "./anonymizer_weights",
    "face_threshold": 0.3,
    "plate_threshold": 0.3,
    "obfuscation_kernel": "65,3,19",

    "labeling_input_dir": "./anonymized_images",
    "anylabeling_venv": "x-anylabeling_env",
    "anylabeling_repo": "~/Object_Detection/X-AnyLabeling",
    "deleted_empty_labels_dir": "./deleted/empty_labels",

    "consolidated_output_dir": "./Dataset",
    "include_labels": true,
    "copy_files": true,
    "label_format": "json",

    "autolabel_input_dir": "./extracted_frames",
    "autolabel_confidence": 0.33,
    "autolabel_iou": 0.7,
    "autolabel_imgsz": 640,
    "autolabel_device": "0",
    "autolabel_delete_unlabeled": true,
    "autolabel_deleted_dir": "./deleted/unlabeled",
    "autolabel_output_dir": "./autolabeled",
    "yolo_train_ratio": 0.8,
    "yolo_classes_file": null,

    "train_epochs": 150,
    "train_batch": 16,
    "train_imgsz": 640,
    "train_device": "",
    "train_workers": 8,
    "train_project": "./runs",
    "train_name": null,
    "train_resume": false,
    "train_pretrained": true,
    "train_optimizer": "auto",
    "train_lr0": 0.01,
    "train_patience": 100,
    "train_cache": false,
    "train_amp": true,
    "train_augment": true
}
